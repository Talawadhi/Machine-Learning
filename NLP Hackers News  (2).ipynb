{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hacker News is a social news website focusing on computer science and entrepreneurship. It has a community where users can submit articles, and other users can upvote those articles. Like other website the articles with the most upvotes make it to the front page.\n",
    "\n",
    "This data set consists of submissions users made to Hacker News from 2006 to 2015. Developer Arnaud Drizard used the Hacker News API to scrape the data, which which can be  found in one of his GitHub repositories. https://github.com/arnauddri/hn\n",
    "\n",
    "hn_stories is a 3000 rows that was sampled from the data randomly, and it has only has four columns:\n",
    "\n",
    "* submission_time - When the article was submitted\n",
    "* upvotes - The number of upvotes the article received\n",
    "* url - The base URL of the article\n",
    "* headline - The article's headline\n",
    "\n",
    "I'll be predicting the number of upvotes the articles received, based on their headlines. \n",
    "Upvotes are an indicator of popularity, I will try to discover which types of articles tend to be the most popular it this community."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Reading the file to datframe\n",
    "articals = pd.read_csv(\"hn_stories.csv\")\n",
    "articals.columns = [\"submission_time\", \"upvotes\", \"url\", \"headline\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>submission_time</th>\n",
       "      <th>upvotes</th>\n",
       "      <th>url</th>\n",
       "      <th>headline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-02-17T16:57:59Z</td>\n",
       "      <td>1</td>\n",
       "      <td>blog.jonasbandi.net</td>\n",
       "      <td>Software: Sadly we did adopt from the construc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-02-04T02:36:30Z</td>\n",
       "      <td>1</td>\n",
       "      <td>blogs.wsj.com</td>\n",
       "      <td>Google’s Stock Split Means More Control for L...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-10-26T07:11:29Z</td>\n",
       "      <td>1</td>\n",
       "      <td>threatpost.com</td>\n",
       "      <td>SSL DOS attack tool released exploiting negoti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-04-03T15:43:44Z</td>\n",
       "      <td>67</td>\n",
       "      <td>algorithm.com.au</td>\n",
       "      <td>Immutability and Blocks Lambdas and Closures</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-01-13T16:49:20Z</td>\n",
       "      <td>1</td>\n",
       "      <td>winmacsofts.com</td>\n",
       "      <td>Comment optimiser la vitesse de Wordpress?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        submission_time  upvotes                  url  \\\n",
       "0  2010-02-17T16:57:59Z        1  blog.jonasbandi.net   \n",
       "1  2014-02-04T02:36:30Z        1        blogs.wsj.com   \n",
       "2  2011-10-26T07:11:29Z        1       threatpost.com   \n",
       "3  2011-04-03T15:43:44Z       67     algorithm.com.au   \n",
       "4  2013-01-13T16:49:20Z        1      winmacsofts.com   \n",
       "\n",
       "                                            headline  \n",
       "0  Software: Sadly we did adopt from the construc...  \n",
       "1   Google’s Stock Split Means More Control for L...  \n",
       "2  SSL DOS attack tool released exploiting negoti...  \n",
       "3       Immutability and Blocks Lambdas and Closures  \n",
       "4         Comment optimiser la vitesse de Wordpress?  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exploring the data\n",
    "articals.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2999 entries, 0 to 2998\n",
      "Data columns (total 4 columns):\n",
      "submission_time    2999 non-null object\n",
      "upvotes            2999 non-null int64\n",
      "url                2810 non-null object\n",
      "headline           2989 non-null object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 93.8+ KB\n"
     ]
    }
   ],
   "source": [
    "\n",
    "articals.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see here, we have four columns three with an object data type and one numerical.\n",
    "\n",
    "There are some missing values, so I am going to remove those rows first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "articals = articals.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "Since I am going to train a linear regression model to predicts the number of upvotes a headline would receive, I will need to convert each headline to a numerical representation.\n",
    "There are several ways to do this, I will use the bag of words model where each piece of text is represented as a numerical vector.\n",
    "The first step in creating a bag of words model is tokenization. I am going to split each sentence into a list of individual words on the space character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a list for the tokens\n",
    "headline_tokens = []\n",
    "\n",
    "# Looping through the dataframe to split headlines and add words as a list \n",
    "for row in articals['headline']:\n",
    "    headline_tokens.append(row.split())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Software:',\n",
       "  'Sadly',\n",
       "  'we',\n",
       "  'did',\n",
       "  'adopt',\n",
       "  'from',\n",
       "  'the',\n",
       "  'construction',\n",
       "  'analogy'],\n",
       " ['Google’s',\n",
       "  'Stock',\n",
       "  'Split',\n",
       "  'Means',\n",
       "  'More',\n",
       "  'Control',\n",
       "  'for',\n",
       "  'Larry',\n",
       "  'and',\n",
       "  'Sergey']]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headline_tokens[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "On my next step, I am going to remove punctuation lowercas all words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['software',\n",
       "  'sadly',\n",
       "  'we',\n",
       "  'did',\n",
       "  'adopt',\n",
       "  'from',\n",
       "  'the',\n",
       "  'construction',\n",
       "  'analogy'],\n",
       " ['googles',\n",
       "  'stock',\n",
       "  'split',\n",
       "  'means',\n",
       "  'more',\n",
       "  'control',\n",
       "  'for',\n",
       "  'larry',\n",
       "  'and',\n",
       "  'sergey']]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A list of punctuation to be removed from tokens\n",
    "punctuation = [ \"/\", \"-\", \"+\", \"&\", \"(\", \")\", \",\", \":\", \";\", \".\", \"'\", '\"', \"’\", \"?\"]\n",
    "\n",
    "# New list for the processed tokens\n",
    "clean_tokens = []\n",
    "\n",
    "# A loop to go through tokens and lower case each word and remove punctuation \n",
    "for tokens in headline_tokens:\n",
    "    #list for each sentance\n",
    "    tokens_list = []\n",
    "    for token in tokens:\n",
    "        token = token.lower()\n",
    "        for p in punctuation:\n",
    "            token = token.replace(p, '')\n",
    "        tokens_list.append(token)\n",
    "    clean_tokens.append(tokens_list)\n",
    "    \n",
    "clean_tokens[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "Now I am going to create a dataframe for all the unique words to convert the sentences to their numerical representations.\n",
    "I will only keep tokens that occured more than one time, tokens that only occurred once don't add to the model's prediction power."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# A list for tokens that only occured once\n",
    "single_tokens = []\n",
    "# List for unique tokens\n",
    "unique_tokens = []\n",
    "\n",
    "# loop through the clean tokens list to add the unique once\n",
    "for tokens in clean_tokens:\n",
    "    for token in tokens:\n",
    "        if token not in single_tokens:\n",
    "            single_tokens.append(token)\n",
    "        elif token not in unique_tokens:\n",
    "            unique_tokens.append(token)\n",
    "\n",
    "# creating a dataframe for all unique tokens as columns names and intialize it with 0 and same size as the clean_tokens list\n",
    "tokens_df = pd.DataFrame(0, index=np.arange(len(clean_tokens)), columns = unique_tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2800 entries, 0 to 2799\n",
      "Columns: 2310 entries, and to disaster\n",
      "dtypes: int64(2310)\n",
      "memory usage: 49.4 MB\n"
     ]
    }
   ],
   "source": [
    "tokens_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "I will loop through the dataframe I just created and add 1 to the tokens if it is in the list of unique tokens\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, tokens in enumerate(clean_tokens):\n",
    "    for token in tokens:\n",
    "        if token in unique_tokens:\n",
    "            tokens_df.iloc[index][token] += 1\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>and</th>\n",
       "      <th>for</th>\n",
       "      <th>as</th>\n",
       "      <th>you</th>\n",
       "      <th>is</th>\n",
       "      <th>the</th>\n",
       "      <th>split</th>\n",
       "      <th>good</th>\n",
       "      <th>how</th>\n",
       "      <th>what</th>\n",
       "      <th></th>\n",
       "      <th>of</th>\n",
       "      <th>de</th>\n",
       "      <th>in</th>\n",
       "      <th>a</th>\n",
       "      <th>with</th>\n",
       "      <th>amazon</th>\n",
       "      <th>cloud</th>\n",
       "      <th>at</th>\n",
       "      <th>google</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   and  for  as  you  is  the  split  good  how  what     of  de  in  a  with  \\\n",
       "0    0    0   0    0   0    1      0     0    0     0  0   0   0   0  0     0   \n",
       "1    1    1   0    0   0    0      1     0    0     0  0   0   0   0  0     0   \n",
       "2    0    0   0    0   0    0      0     0    0     0  0   0   0   0  0     0   \n",
       "3    2    0   0    0   0    0      0     0    0     0  0   0   0   0  0     0   \n",
       "4    0    0   0    0   0    0      0     0    0     0  0   0   1   0  0     0   \n",
       "5    0    1   2    2   1    0      0     1    0     0  0   0   0   0  0     0   \n",
       "6    0    0   0    0   0    0      0     0    0     0  1   0   0   0  0     0   \n",
       "7    0    1   0    0   0    0      0     0    0     0  0   0   0   0  0     0   \n",
       "8    0    0   0    0   0    0      0     0    0     0  0   0   0   0  0     0   \n",
       "9    0    0   0    0   0    0      0     0    1     0  0   0   0   0  0     0   \n",
       "\n",
       "   amazon  cloud  at  google  \n",
       "0       0      0   0       0  \n",
       "1       0      0   0       0  \n",
       "2       0      0   0       0  \n",
       "3       0      0   0       0  \n",
       "4       0      0   0       0  \n",
       "5       0      0   0       0  \n",
       "6       0      0   0       0  \n",
       "7       0      0   0       0  \n",
       "8       0      0   0       0  \n",
       "9       0      0   0       0  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_df.iloc[:10,:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To further inhance my prediciton, I am going to remove words that occured more than 100 times which should remove stopwords like 'and' and 'for', which occurs almost in every headline and words that occured less than 5 times. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the sum of each token occurrence \n",
    "word_counts = tokens_df.sum(axis = 0)\n",
    "\n",
    "# remove tokens fewer than 5 and more than 100\n",
    "tokens_df = tokens_df.loc[:, (word_counts >= 5) & (word_counts <= 100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2800 entries, 0 to 2799\n",
      "Columns: 661 entries, as to nike\n",
      "dtypes: int64(661)\n",
      "memory usage: 14.1 MB\n"
     ]
    }
   ],
   "source": [
    "tokens_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we reduced tokens from 2310 to 661"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will split the data into two sets: 80% training set and 20% test set, \n",
    "and I will use the train_test_split function from sckit-learn to do that \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(tokens_df, articals['upvotes'], test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# initializing the linear regression model\n",
    "lr = LinearRegression()\n",
    "\n",
    "# Fitting the model\n",
    "lr.fit(x_train, y_train)\n",
    "\n",
    "# Calculating predictions on the test data\n",
    "predictions = lr.predict(x_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean =  10.32407204900292\n",
      "Srandard Deviation =  29.084076705842442\n",
      "Mean Squared Error =  1815.5326272886325\n",
      "Squared root of mse =  42.60906743040303\n"
     ]
    }
   ],
   "source": [
    "\n",
    "mean = np.mean(predictions)\n",
    "std  = np.std(predictions)\n",
    "mse = mean_squared_error(predictions, y_test)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print('Mean = ', mean)\n",
    "print('Srandard Deviation = ', std)\n",
    "print('Mean Squared Error = ', mse)\n",
    "print('Squared root of mse = ', rmse)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean squared error is 1815 which is a fairly larg number. The mean  of upvotes is 10, and the standard deviation is 29.\n",
    "The square root of mse is 42.6 which means that the average error is 46 upvotes away from the true value which higher than the standard deviation, so my predictions are off-base.\n",
    "I will try a random forest model, maybe I can get better results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean =  6.1553571428571425\n",
      "Srandard deviation =  36.77478474076486\n",
      "Mean squared error =  2353.6696428571427\n",
      "Squared root of mse =  48.51463328581535\n"
     ]
    }
   ],
   "source": [
    "# initializing the the model\n",
    "rf = RandomForestClassifier(random_state = 1)\n",
    "\n",
    "#fitting the model\n",
    "rf.fit(x_train, y_train)\n",
    "\n",
    "# Calculating predictions\n",
    "predictions = rf.predict(x_test)\n",
    "\n",
    "mean = np.mean(predictions)\n",
    "std  = np.std(predictions)\n",
    "mse = mean_squared_error(predictions, y_test)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print('Mean = ', mean)\n",
    "print('Srandard deviation = ', std)\n",
    "print('Mean squared error = ', mse)\n",
    "print('Squared root of mse = ', rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The random forest rmse is 48.5 which is more than what I got from the regression model. \n",
    "I will leave it for now and try to do some more features engineering and hyperparameter optimization in the future to get a better result. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
